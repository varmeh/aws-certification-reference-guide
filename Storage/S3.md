- [S3 - Simple Storage Service](#s3---simple-storage-service)
  - [What's S3](#whats-s3)
    - [Guarantees](#guarantees)
    - [Features](#features)
    - [Data Consistency for S3](#data-consistency-for-s3)
  - [S3 Buckets](#s3-buckets)
    - [Creating a bucket](#creating-a-bucket)
    - [Managing public access](#managing-public-access)
    - [Accessing a bucket](#accessing-a-bucket)
    - [Bucket Configuration Options](#bucket-configuration-options)
    - [Bucket Encryption](#bucket-encryption)
    - [Bucket Restrictions & Limitations](#bucket-restrictions--limitations)
    - [Requester Pays Buckets](#requester-pays-buckets)
    - [Billing](#billing)
    - [Transfer Acceleration](#transfer-acceleration)
  - [S3 Objects](#s3-objects)
    - [Object Key & Metadata](#object-key--metadata)
    - [Object Versioning](#object-versioning)
    - [Object Tagging](#object-tagging)
    - [Object Subresources](#object-subresources)
    - [Object Lifecycle](#object-lifecycle)
    - [Operations on Objects](#operations-on-objects)
    - [Object Storage Classes](#object-storage-classes)
  - [S3 Security](#s3-security)
    - [Data Encryption](#data-encryption)
    - [IAM for S3](#iam-for-s3)
    - [Resilience](#resilience)
      - [Versioning](#versioning)
      - [Locking Objects](#locking-objects)
      - [Security Best Practices](#security-best-practices)
  - [Cross Region Replication](#cross-region-replication)
  - [Good to Know](#good-to-know)
  - [Misc Questions](#misc-questions)

# S3 - Simple Storage Service

## [What's S3](https://docs.aws.amazon.com/AmazonS3/latest/dev/Introduction.html)

Amazon S3 is object storage built to store and retrieve any amount of data from anywhere on the Internet.

It is an object storage service that offers industry-leading scalability, data availability, security, and performance.

- Object-based storage: you can save only object (_read files_), you can't, for example, install an OS (In this case you need block-based storage)
- Files are stored in a **Bucket** (folder in cloud)
- **S3 is a universal namespace**, so bucket name must be unique globally
- By default, all buckets when created are PRIVATE.
- Files can save from 0 Bytes to 5 TB
- No storage Limits. Store as many files as you want
- **Amazon S3 data model is a flat structure**
  - You create a bucket, and the bucket stores objects
  - There is no hierarchy of subbuckets or subfolders
- Sample of an S3 URL for bucket *varmeh* & object *photo.jpg*: 
  - Path Style Url: `https://s3-eu-west-1.amazonaws.com/varmeh/photo.jpg`
  - Virtual Hosted Style Url: `https://varmeh.s3-eu-west-1.amazonaws.com//photo.jpg`
- For a successful upload an object in S3, you get an HTTP 200 status code back
- Your Amazon S3 resources (for example buckets and objects) are private by default
- S3 refined performance
  - 3,500 requests per sec to add data (*PUTS for new objects*)
  - 5,500 requests per to retrieve data (*GET/HEAD Requests*)


### Guarantees

- _Availability_: Built for 99.9% availability
- _Durability_: S3 guarantees 11x9s (99.999999999) durability for S3 information

### Features

- Tiered Storage (classes) available
- Lifecycle Management - Move files between different S3 tiers
- Versioning
- Supports [multi-part upload](https://docs.aws.amazon.com/AmazonS3/latest/dev/mpuoverview.html)
- Encryption
- MFA (Multi-Factor Authentication) Delete
- **Access Control** (_permissions on single files_) and **Bucket Policies** (_permissions on buckets_)
  

### [Data Consistency for S3](https://docs.aws.amazon.com/AmazonS3/latest/dev/Introduction.html#ConsistencyModel)

- _Read after Write Consistency for PUTS of new Objects_: PUTS is used to create new objects. It's consistent in reads after a write on new objects
- _Eventual Consistency for overwrite PUTS & DELETE_: It's eventually consistent for overwriting and deletes i.e. it can take some time to propagate
- _Atomic Updates_: if you PUT to an existing key, a subsequent read might return the old data or the updated data, but it will never return corrupted or partial data
- S3 is spread across multiple AZ's

## S3 Buckets

### [Creating a bucket](https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingBucket.html#create-bucket-intro)

### [Managing public access](https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingBucket.html#block-public-access-intro)

### [Accessing a bucket](https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingBucket.html#access-bucket-intro)
  - Note distinction between **a virtual-hosted–style URL** & **a path-style URL**

### [Bucket Configuration Options](https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingBucket.html#bucket-config-options-intro)

### [Bucket Encryption](https://docs.aws.amazon.com/AmazonS3/latest/dev/bucket-encryption.html)

### [Bucket Restrictions & Limitations](https://docs.aws.amazon.com/AmazonS3/latest/dev/BucketRestrictions.html)

- A bucket is owned by the AWS account that created it
- By default, you can create up to 100 buckets in each of your AWS accounts
- This limit could be increased to a maximum of 1,000 buckets by submitting a service limit increase
- Bucket ownership is not transferable
- You cannot create a bucket within another bucket
- [Rules for bucket naming](https://docs.aws.amazon.com/AmazonS3/latest/dev/BucketRestrictions.html#bucketnamingrules)

### [Requester Pays Buckets](https://docs.aws.amazon.com/AmazonS3/latest/dev/RequesterPaysBuckets.html)

### [Billing](https://docs.aws.amazon.com/AmazonS3/latest/dev/BucketBilling.html)

- [Charges associated with S3 usage](https://docs.aws.amazon.com/AmazonS3/latest/dev/aws-billing-reports.html)
  - **Monitoring & Automation Charges** for **INTELLIGENT_TIERING** objects
  - Charges on **Early Deletion**
  - **Storage Management Fees**


### [Transfer Acceleration](https://docs.aws.amazon.com/AmazonS3/latest/dev/transfer-acceleration.html)

- It enables fast, easy and secure **uploads** of files over long distances between client and an S3 bucket
- Transfer Acceleration takes advantage of **Amazon CloudFront’s globally distributed edge locations**
- *Instead of uploading directly to S3 bucket*, user uploads to an Edge location which will then transfer the file to S3
- User get a distinct Url to upload (_one of Edge location, instead of bucket_)


## [S3 Objects](https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingObjects.html)

### [Object Key & Metadata](https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingMetadata.html)
  
Each Amazon S3 object has following:
- **Key** (name of the object)
- **Value** (data)
- **Version ID** (Used for versioning)
- **Metadata** (a set of data that describes and gives information about the object data)
  - *User Defined Metadata*
    - When you upload objects using the REST API, the optional user-defined metadata names must begin with *"x-amz-meta-"* to distinguish them from other HTTP headers
  - *System Defined Metadata*
- **Subresources**:
  - *Access Control List* (for access control at object level)
  - *Torrent* (Not an exam topic)
    
### [Object Versioning](https://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectVersioning.html)

- By default, versioning is disabled
- Each bucket has a default *Version Id* set to *null*
- If you have enabled versioning, Amazon S3 assigns a unique version ID value for the object
- When you enable versioning on a bucket, objects already stored in the bucket are unchanged. The version IDs (null), contents, and permissions remain the same
- Enabling and suspending versioning is done at the bucket level
- Amazon S3 generates version IDs. They cannot be edited
- When you DELETE an object, all versions remain in the bucket and Amazon S3 inserts a delete marker
- Performing a simple GET Object request when the current version is a delete marker returns a *404 Not Found* error
- You can permanently delete an object by specifying the version you want to delete

### [Object Tagging](https://docs.aws.amazon.com/AmazonS3/latest/dev/object-tagging.html)

- You can associate up to 10 tags with an object
- Tags associated with an object must have unique tag keys
- Key and values are case sensitive

### [Object Subresources](https://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectAndSoubResource.html)

### [Object Lifecycle](https://docs.aws.amazon.com/AmazonS3/latest/dev/object-lifecycle-mgmt.html)
  
- It is used to manage objects tiers so that they are stored cost effectively throughout their lifecycle
- A lifecycle configuration is a set of rules that define **actions** that Amazon S3 applies to a group of objects
- These actions are intended to reduce usage cost. So, transitions are allowed only **from higher cost to lower cost storage tier**

- [Transitioning Objects Using Amazon S3 Lifecycle](https://docs.aws.amazon.com/AmazonS3/latest/dev/lifecycle-transition-general-considerations.html)
  - Look into Supported transitions
  - *Allowed Transitions*:
    - STANDARD storage class to any other storage class
    - STANDARD_IA to INTELLIGENT_TIERING or ONEZONE_IA
    - INTELLIGENT_TIERING to ONEZONE_IA
    - Any storage class to GLACIER or DEEP_ARCHIEVE
    - GLACIER to DEEP_ARCHIEVE

- [Configuring Object Expiration](https://docs.aws.amazon.com/AmazonS3/latest/dev/lifecycle-expire-general-considerations.html)
  - When an object reaches the end of its lifetime, Amazon S3 queues it for removal and removes it asynchronously

- [Lifecycle & Other Bucket Configurations](https://docs.aws.amazon.com/AmazonS3/latest/dev/lifecycle-and-other-bucket-config.html)

- [Lifecycle Rules Configuration](https://docs.aws.amazon.com/AmazonS3/latest/dev/intro-lifecycle-rules.html)

- [Examples of Lifecyle Configuration](https://docs.aws.amazon.com/AmazonS3/latest/dev/lifecycle-configuration-examples.html)

### [Operations on Objects](https://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectOperations.html)

- Amazon S3 enables you to store, retrieve, and delete objects
- You can retrieve an entire object or a portion of an object
- If you have enabled versioning on your bucket, you can retrieve a specific version of the object
- You can also retrieve a subresource associated with your object and update it where applicable
- You can make a copy of your existing object
  
- **Supported Operations** (*For quick browsing. Not important from exam perspective*):
  - [Getting Objects](https://docs.aws.amazon.com/AmazonS3/latest/dev/GettingObjectsUsingAPIs.html)
  - [Uploading Objects](https://docs.aws.amazon.com/AmazonS3/latest/dev/UploadingObjects.html)
  - [Copying Objects](https://docs.aws.amazon.com/AmazonS3/latest/dev/CopyingObjectsExamples.html)
  - [Listing Object Keys](https://docs.aws.amazon.com/AmazonS3/latest/dev/ListingKeysUsingAPIs.html)
  - [Deleting Objects](https://docs.aws.amazon.com/AmazonS3/latest/dev/DeletingObjects.html)
  - [Selecting Content from Objects](https://docs.aws.amazon.com/AmazonS3/latest/dev/selecting-content-from-objects.html)
  - [Restoring Archived Objects](https://docs.aws.amazon.com/AmazonS3/latest/dev/restoring-objects.html)
  - [Querying Archived Objects](https://docs.aws.amazon.com/AmazonS3/latest/dev/querying-glacier-archives.html)

### [Object Storage Classes](https://docs.aws.amazon.com/AmazonS3/latest/dev/storage-class-intro.html)

Each object in Amazon S3 has a storage class associated with it.

Amazon S3 offers a range of storage classes for the objects that you store. You choose a class depending on your use case scenario and performance access requirements.

- **Storage Classes for Frequently Accessed Objects**

  - **STANDARD**: 99.99% availability, 11x9s durability. It can sustain the loss of 2 facilities concurrently
  - **REDUCED_REDUNDANCY**: designed for noncritical, reproducible data (*It is being phased out*)

- **Storage Class That Automatically Optimizes Frequently and Infrequently Accessed Objects**
  
  - **INTELLIGENT_TIERING**: 
    - Designed to optimized costs by automatically moving data to most cost effective tier access, without performance degrade or operational overhead
    - Delivers automatic cost savings by moving data on a granular object level between two access tiers, *a frequent access tier* and *a lower-cost infrequent access tier*   

- **Storage Classes for Infrequently Accessed Objects**
  - **STANDARD_IA**: (_Infrequently Accessed_) For data that is accessed less frequently, but needs rapid access. You are charged a retrieval fee per GB retrieved
  - **ONEZONE_IA**: 
    - Like S3 IA but data is stored only in one Availability Zone
    - Availability - 99.50%

- **Storage Classes for Archiving Objects**
  - **GLACIER**: It for data archieving. Very reasonable in terms of costs. _Retrieval times configurable from minutes to hrs_. It has been further divided into 3 categories:

    - _Expedited_: few minutes for retrieval
    - _Standard_: 3-5 hours for retrieval
    - _Bulk_: 5-12 hours for retrieval

  - **DEEP_ARCHIVE**: long term storage with lowest retrival cost & retrieval time of upto 48 hrs


## [S3 Security](https://docs.aws.amazon.com/AmazonS3/latest/dev/security.html)

Amazon follows a [Shared Responsibility Model](https://aws.amazon.com/compliance/shared-responsibility-model/) for Security.

This model divides security in 2 parts:

- **Security of the cloud**: AWS is responsible for protecting the infrastructure that runs AWS services in the AWS Cloud
- **Security in the cloud**:  Customers are responsible for managing their data (*including encryption options*), classifying their assets, and using IAM tools to apply the appropriate permissions.

### [Data Encryption](https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingEncryption.html)

Two types of encryption involved:

- **Encryption in Transit**:

  - Refers to secure communication over internet
  - Mainly achieved by HTTPS
  - Encryption used for HTTPS is **SSL/TLS**

- **Encryption at Rest**:

  - Save the data on cloud after encrypting it
  - It could be achieved in 2 ways:

    - **Client Side Encryption**:

      - *Client-side encryption* is the act of encrypting data before sending it to Amazon S3
      - Encrypt data client-side and upload the encrypted data to Amazon S3
      - In this case, developer manages the encryption process, the encryption keys, and related tools

    - **[Server Side Encryption](https://docs.aws.amazon.com/AmazonS3/latest/dev/serv-side-encryption.html)**:

      - Request Amazon S3 to encrypt your object before saving it on disks in its data centers and then decrypt it when you download the objects
      - AES-256 Encryption
      - **3 mutually exclusive** options to manage your encryption keys:

        - [Use Server-Side Encryption with Amazon S3-Managed Keys (SSE-S3)](https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingServerSideEncryption.html):

          - It provides an integrated solution where Amazon handles key management and key protection using multiple layers of security
          - Each object is encrypted with a unique key
          - As an additional safeguard, it encrypts the key itself with a master key that it regularly rotates

        - [Use Server-Side Encryption with AWS KMS-Managed Keys (SSE-KMS)](https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html):

          - It enables you to use AWS Key Management Service (AWS KMS) to manage your encryption keys
          - AWS KMS uses customer master keys (CMKs) to encrypt your Amazon S3 objects
          - AWS KMS provides an audit trail so you can see who used your key to access which object and when, as well as view failed attempts to access data from users without permission to decrypt the data
          - You can choose to create and manage encryption keys yourself, or you can choose to use your default service key uniquely generated on a customer by service by Region level

        - [Use Server-Side Encryption with Customer-Provided Keys (SSE-C)](https://docs.aws.amazon.com/AmazonS3/latest/dev/ServerSideEncryptionCustomerKeys.html):

          - SSE-C enables you to leverage Amazon S3 to perform the encryption and decryption of your objects while retaining control of the keys used to encrypt objects
          - Here customer provides encryption/decryption keys
          - Customer manages a mapping of which encryption key was used to encrypt which object

### [IAM for S3](https://docs.aws.amazon.com/AmazonS3/latest/dev/s3-access-control.html)

- [Managing Access to S3 Resources](https://docs.aws.amazon.com/AmazonS3/latest/dev/access-control-overview.html)
  
- By default, all Amazon S3 resources—buckets, objects, and related subresources (eg, *lifecycle configuration and website configuration*) are *private*
- Which means only the resource owner, an AWS account that created it, can access the resource
- The resource owner can optionally grant access permissions to others by writing an **access policy**
- 2 types of access policies:
  - **Resource-based policies**: Access policies attach to the resources. eg. *bucket policies*, *access control lists*
  - **[User policies](https://docs.aws.amazon.com/AmazonS3/latest/dev/walkthrough1.html)**: Access policies attached to users in your account

- [Guidelines for Using Available Policy Options](https://docs.aws.amazon.com/AmazonS3/latest/dev/access-policy-alternatives-guidelines.html)

- [Access Control List Overview](https://docs.aws.amazon.com/AmazonS3/latest/dev/acl-overview.html)
  - [How to set ACL Bucket Permissions?](https://docs.aws.amazon.com/AmazonS3/latest/user-guide/set-bucket-permissions.html)
  - [How to set permissions on an Object?](https://docs.aws.amazon.com/AmazonS3/latest/user-guide//set-object-permissions.html)

- [S3 Block Public Access](https://docs.aws.amazon.com/AmazonS3/latest/dev/access-control-block-public-access.html)

### [Resilience](https://docs.aws.amazon.com/AmazonS3/latest/dev/disaster-recovery-resiliency.html)

#### [Versioning](https://docs.aws.amazon.com/AmazonS3/latest/dev/Versioning.html)

- Stores all versions of an object, including the over-written & deleted one's as well
- Use versioning to preserve, retrieve, and restore every version of every object stored in your Amazon S3 bucket
- Once enabled, **Versioning can't be disabled**, only suspended
- _Updated version of an object is PRIVATE by default_. Permissions of older versions are kept intact. In essence, each version access is independent to others
- It integrates with Lifecycle rules
- *You pay for each version you have*
- Delete an object:
  - Once you delete a file inside a versioned bucket, file is not deleted. Instead, a _Delete Marker_ is added to file metadata (_this basically creates a new version of the object_)
  - Deleting the version with the _Delete Marker_ will basically restore the object
  - To permanently delete a versioned object, delete all the Versions of the object


*Effect of different operations on Objects in a versioned bucket*:

  - Managing Objects in a **Versioning-Enabled Bucket**
    - [Adding Object](https://docs.aws.amazon.com/AmazonS3/latest/dev/AddingObjectstoVersioningEnabledBuckets.html)
    - [Listing Objects](https://docs.aws.amazon.com/AmazonS3/latest/user-guide/view-object-versions.html)
    - [Retrieving Object Versions](https://docs.aws.amazon.com/AmazonS3/latest/dev/RetrievingObjectVersions.html)
    - [Deleting Object Versions](https://docs.aws.amazon.com/AmazonS3/latest/dev/DeletingObjectVersions.html)
      - [Delete Marker](https://docs.aws.amazon.com/AmazonS3/latest/dev/DeleteMarker.html)
      - [Removing Delete Markers](https://docs.aws.amazon.com/AmazonS3/latest/dev/RemDelMarker.html)
    - [Restoring Previous Versions](https://docs.aws.amazon.com/AmazonS3/latest/dev/RestoringPreviousVersions.html)
    - Versioned Object Permissions
      - Permissions are set at the version level
      - Each version has its own object owner
      - Different permissions could be set for different versions of the same object

  - Managing Objects in a **Versioning-Suspended Bucket**
    - [Adding Objects](https://docs.aws.amazon.com/AmazonS3/latest/dev/AddingObjectstoVersionSuspendedBuckets.html)
    - [Retrieving Object](https://docs.aws.amazon.com/AmazonS3/latest/dev/RetrievingObjectsfromVersioningSuspendedBuckets.html)
    - [Deleting Object](https://docs.aws.amazon.com/AmazonS3/latest/dev/DeletingObjectsfromVersioningSuspendedBuckets.html)

#### [Locking Objects](https://docs.aws.amazon.com/AmazonS3/latest/dev/object-lock.html)

#### [Security Best Practices](https://docs.aws.amazon.com/AmazonS3/latest/dev/security-best-practices.html)

## [Cross Region Replication](https://docs.aws.amazon.com/AmazonS3/latest/dev/crr.html)

- Versioning must be enabled for both source & destination buckets
- Regions must be unique
- Files in an existing bucket are not replicated automatically
- All subsequent new/updated files would be replicated automatically
- In order to replicate the existing objects, you need to do a manual copy
- If you delete an object in the primary bucket, the delete action and *Delete Markers* won't be replicated in destination bucket. Only creations and modifications are replicated & not Delete
- You can't replicate over multiple buckets, the maps are always 1-to-1

- [Object Replication](https://docs.aws.amazon.com/AmazonS3/latest/dev/crr-what-is-isnot-replicated.html)


## Good to Know

*Following topics are not relevant from certification point of view.*

But it's good to have an idea of all options in S3:

- [Static Website Hosting](https://docs.aws.amazon.com/AmazonS3/latest/dev/WebsiteHosting.html)
- [S3 Analytics](https://docs.aws.amazon.com/AmazonS3/latest/dev/analytics-storage-class.html)
- [Event Notification](https://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html)
- [Monitoring](https://docs.aws.amazon.com/AmazonS3/latest/dev/monitoring-overview.html)
- [Performance Guidelines for Amazon S3](https://docs.aws.amazon.com/AmazonS3/latest/dev/optimizing-performance-guidelines.html)
- [Performance Design Patterns for Amazon S3](https://docs.aws.amazon.com/AmazonS3/latest/dev/optimizing-performance-design-patterns.html)

## Misc Questions

- [S3 Expiry and Permanently delete Lifecycle rules](https://acloud.guru/forums/aws-csa-2019/discussion/-Ligt1fcro5OloaS6CwN/s3_expiry_and_permanently_dele)
- [Lifecycle vs Intelligent Tiering](https://aws.amazon.com/blogs/aws/new-automatic-cost-optimization-for-amazon-s3-via-intelligent-tiering/)
- [S3 Increased Request Rate Performance](https://aws.amazon.com/about-aws/whats-new/2018/07/amazon-s3-announces-increased-request-rate-performance/)
- [Customer does not want to upload encryption keys to AWS. Which encryption option should be used?](https://acloud.guru/forums/aws-csa-2019/discussion/-Lila0bsbx0h0YzGgHPz/s3_encryption_question)
